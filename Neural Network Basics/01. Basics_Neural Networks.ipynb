{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of MLP\n",
    "- Objective: create vanilla neural networks (i.e., Multilayer perceptrons) for simple regression/classification tasks with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Structures\n",
    "- Each MLP model is consisted of one input layer, several hidden layers, and one output layer\n",
    "- Number of neurons in each layer is not limited\n",
    "<img src=\"http://cs231n.github.io/assets/nn1/neural_net.jpeg\" style=\"width: 300px\"/>\n",
    "<br>\n",
    "<center>**MLP with one hidden layer**</center>\n",
    "- Number of input neurons: 3\n",
    "- Number of hidden neurons: 4\n",
    "- Number of output neurons: 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cs231n.github.io/assets/nn1/neural_net2.jpeg\" style=\"width: 500px\"/>\n",
    "<br>\n",
    "<center>**MLP with two hidden layers**</center>\n",
    "- Number of input neurons: 3\n",
    "- Number of hidden neurons: (4, 4)\n",
    "- Number of output neurons: 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP for Regression tasks\n",
    "- When the target (**y**) is continuous (real)\n",
    "- For loss function and evaluation metric, mean squared error (MSE) is commonly used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/keras-datasets/boston_housing.npz\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description\n",
    "- Boston housing dataset has total 506 data instances (404 training & 102 test)\n",
    "- 13 attributes (features) to predict \"the median values of the houses at a location\"\n",
    "- Doc: https://keras.io/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "(102, 13)\n",
      "(404,)\n",
      "(102,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creating a model\n",
    "- Keras model object can be created with Sequential class\n",
    "- At the outset, the model is empty per se. It is completed by **'adding'** additional layers and compilation\n",
    "- Doc: https://keras.io/models/sequential/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Adding layers\n",
    "- Keras layers can be **added** to the model\n",
    "- Adding layers are like stacking lego blocks one by one\n",
    "- Doc: https://keras.io/layers/core/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Keras model with two hidden layer with 10 neurons each \n",
    "model.add(Dense(10, input_shape = (13,)))    # Input layer => input_shape should be explicitly designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1))                          # Output layer => output dimension = 1 since it is regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is equivalent to the above code block\n",
    "model.add(Dense(10, input_shape = (13,), activation = 'sigmoid'))\n",
    "model.add(Dense(10, activation = 'sigmoid'))\n",
    "model.add(Dense(10, activation = 'sigmoid'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Model compile\n",
    "- Keras model should be \"compiled\" prior to training\n",
    "- Types of loss (function) and optimizer should be designated\n",
    "    - Doc (optimizers): https://keras.io/optimizers/\n",
    "    - Doc (losses): https://keras.io/losses/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr = 0.01)    # stochastic gradient descent optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = sgd, loss = 'mean_squared_error', metrics = ['mse'])    # for regression problems, mean squared error (MSE) is often employed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                140       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 622.0\n",
      "Trainable params: 622.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training\n",
    "- Training the model with training data provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "404/404 [==============================] - 0s - loss: 385.4093 - mean_squared_error: 385.4093     \n",
      "Epoch 2/100\n",
      "404/404 [==============================] - 0s - loss: 96.0846 - mean_squared_error: 96.0846       \n",
      "Epoch 3/100\n",
      "404/404 [==============================] - 0s - loss: 85.5623 - mean_squared_error: 85.5623     \n",
      "Epoch 4/100\n",
      "404/404 [==============================] - 0s - loss: 84.8892 - mean_squared_error: 84.8892       \n",
      "Epoch 5/100\n",
      "404/404 [==============================] - 0s - loss: 85.2516 - mean_squared_error: 85.2516     \n",
      "Epoch 6/100\n",
      "404/404 [==============================] - 0s - loss: 85.1706 - mean_squared_error: 85.1706     \n",
      "Epoch 7/100\n",
      "404/404 [==============================] - 0s - loss: 85.9835 - mean_squared_error: 85.9835       \n",
      "Epoch 8/100\n",
      "404/404 [==============================] - 0s - loss: 85.0728 - mean_squared_error: 85.0728       \n",
      "Epoch 9/100\n",
      "404/404 [==============================] - 0s - loss: 84.8822 - mean_squared_error: 84.8822     \n",
      "Epoch 10/100\n",
      "404/404 [==============================] - 0s - loss: 84.8653 - mean_squared_error: 84.8653     \n",
      "Epoch 11/100\n",
      "404/404 [==============================] - 0s - loss: 84.8453 - mean_squared_error: 84.8453     \n",
      "Epoch 12/100\n",
      "404/404 [==============================] - 0s - loss: 87.6947 - mean_squared_error: 87.6947       \n",
      "Epoch 13/100\n",
      "404/404 [==============================] - 0s - loss: 85.0815 - mean_squared_error: 85.0815     \n",
      "Epoch 14/100\n",
      "404/404 [==============================] - 0s - loss: 84.8550 - mean_squared_error: 84.8550     \n",
      "Epoch 15/100\n",
      "404/404 [==============================] - 0s - loss: 84.8168 - mean_squared_error: 84.8168       \n",
      "Epoch 16/100\n",
      "404/404 [==============================] - 0s - loss: 85.7341 - mean_squared_error: 85.7341     \n",
      "Epoch 17/100\n",
      "404/404 [==============================] - 0s - loss: 84.9796 - mean_squared_error: 84.9796       \n",
      "Epoch 18/100\n",
      "404/404 [==============================] - 0s - loss: 85.3332 - mean_squared_error: 85.3332       \n",
      "Epoch 19/100\n",
      "404/404 [==============================] - 0s - loss: 84.7287 - mean_squared_error: 84.7287     \n",
      "Epoch 20/100\n",
      "404/404 [==============================] - 0s - loss: 84.9954 - mean_squared_error: 84.9954     \n",
      "Epoch 21/100\n",
      "404/404 [==============================] - 0s - loss: 85.2005 - mean_squared_error: 85.2005     \n",
      "Epoch 22/100\n",
      "404/404 [==============================] - 0s - loss: 87.4599 - mean_squared_error: 87.4599       \n",
      "Epoch 23/100\n",
      "404/404 [==============================] - 0s - loss: 84.7201 - mean_squared_error: 84.7201     \n",
      "Epoch 24/100\n",
      "404/404 [==============================] - 0s - loss: 85.1760 - mean_squared_error: 85.1760       \n",
      "Epoch 25/100\n",
      "404/404 [==============================] - 0s - loss: 85.6762 - mean_squared_error: 85.6762     \n",
      "Epoch 26/100\n",
      "404/404 [==============================] - 0s - loss: 84.7802 - mean_squared_error: 84.7802     \n",
      "Epoch 27/100\n",
      "404/404 [==============================] - 0s - loss: 84.9257 - mean_squared_error: 84.9257       \n",
      "Epoch 28/100\n",
      "404/404 [==============================] - 0s - loss: 85.3067 - mean_squared_error: 85.3067     \n",
      "Epoch 29/100\n",
      "404/404 [==============================] - 0s - loss: 84.6834 - mean_squared_error: 84.6834     \n",
      "Epoch 30/100\n",
      "404/404 [==============================] - 0s - loss: 84.9257 - mean_squared_error: 84.9257     \n",
      "Epoch 31/100\n",
      "404/404 [==============================] - 0s - loss: 85.1909 - mean_squared_error: 85.1909     \n",
      "Epoch 32/100\n",
      "404/404 [==============================] - 0s - loss: 85.0596 - mean_squared_error: 85.0596     \n",
      "Epoch 33/100\n",
      "404/404 [==============================] - 0s - loss: 84.8472 - mean_squared_error: 84.8472     \n",
      "Epoch 34/100\n",
      "404/404 [==============================] - 0s - loss: 84.7067 - mean_squared_error: 84.7067     \n",
      "Epoch 35/100\n",
      "404/404 [==============================] - 0s - loss: 84.9354 - mean_squared_error: 84.9354       \n",
      "Epoch 36/100\n",
      "404/404 [==============================] - 0s - loss: 85.3147 - mean_squared_error: 85.3147     \n",
      "Epoch 37/100\n",
      "404/404 [==============================] - 0s - loss: 85.2319 - mean_squared_error: 85.2319     \n",
      "Epoch 38/100\n",
      "404/404 [==============================] - 0s - loss: 85.8282 - mean_squared_error: 85.8282     \n",
      "Epoch 39/100\n",
      "404/404 [==============================] - 0s - loss: 86.1568 - mean_squared_error: 86.1568       \n",
      "Epoch 40/100\n",
      "404/404 [==============================] - 0s - loss: 85.3841 - mean_squared_error: 85.3841       \n",
      "Epoch 41/100\n",
      "404/404 [==============================] - 0s - loss: 84.9164 - mean_squared_error: 84.9164     \n",
      "Epoch 42/100\n",
      "404/404 [==============================] - 0s - loss: 85.8085 - mean_squared_error: 85.8085     \n",
      "Epoch 43/100\n",
      "404/404 [==============================] - 0s - loss: 85.3153 - mean_squared_error: 85.3153     \n",
      "Epoch 44/100\n",
      "404/404 [==============================] - 0s - loss: 85.0617 - mean_squared_error: 85.0617     \n",
      "Epoch 45/100\n",
      "404/404 [==============================] - 0s - loss: 85.1184 - mean_squared_error: 85.1184     \n",
      "Epoch 46/100\n",
      "404/404 [==============================] - 0s - loss: 85.2014 - mean_squared_error: 85.2014     \n",
      "Epoch 47/100\n",
      "404/404 [==============================] - 0s - loss: 85.3538 - mean_squared_error: 85.3538       \n",
      "Epoch 48/100\n",
      "404/404 [==============================] - 0s - loss: 85.0292 - mean_squared_error: 85.0292     \n",
      "Epoch 49/100\n",
      "404/404 [==============================] - 0s - loss: 85.0059 - mean_squared_error: 85.0059     \n",
      "Epoch 50/100\n",
      "404/404 [==============================] - 0s - loss: 86.0155 - mean_squared_error: 86.0155       \n",
      "Epoch 51/100\n",
      "404/404 [==============================] - 0s - loss: 84.7618 - mean_squared_error: 84.7618     \n",
      "Epoch 52/100\n",
      "404/404 [==============================] - 0s - loss: 85.5059 - mean_squared_error: 85.5059     \n",
      "Epoch 53/100\n",
      "404/404 [==============================] - 0s - loss: 84.8723 - mean_squared_error: 84.8723     \n",
      "Epoch 54/100\n",
      "404/404 [==============================] - 0s - loss: 85.0834 - mean_squared_error: 85.0834       \n",
      "Epoch 55/100\n",
      "404/404 [==============================] - 0s - loss: 86.9944 - mean_squared_error: 86.9944     \n",
      "Epoch 56/100\n",
      "404/404 [==============================] - 0s - loss: 84.7276 - mean_squared_error: 84.7276     \n",
      "Epoch 57/100\n",
      "404/404 [==============================] - 0s - loss: 85.0388 - mean_squared_error: 85.0388       \n",
      "Epoch 58/100\n",
      "404/404 [==============================] - 0s - loss: 86.2871 - mean_squared_error: 86.2871     \n",
      "Epoch 59/100\n",
      "404/404 [==============================] - 0s - loss: 84.8135 - mean_squared_error: 84.8135     \n",
      "Epoch 60/100\n",
      "404/404 [==============================] - 0s - loss: 85.1962 - mean_squared_error: 85.1962     \n",
      "Epoch 61/100\n",
      "404/404 [==============================] - 0s - loss: 85.2153 - mean_squared_error: 85.2153     \n",
      "Epoch 62/100\n",
      "404/404 [==============================] - 0s - loss: 85.3012 - mean_squared_error: 85.3012       \n",
      "Epoch 63/100\n",
      "404/404 [==============================] - 0s - loss: 85.7592 - mean_squared_error: 85.7592     \n",
      "Epoch 64/100\n",
      "404/404 [==============================] - 0s - loss: 85.7286 - mean_squared_error: 85.7286     \n",
      "Epoch 65/100\n",
      "404/404 [==============================] - 0s - loss: 84.8016 - mean_squared_error: 84.8016     \n",
      "Epoch 66/100\n",
      "404/404 [==============================] - 0s - loss: 85.3277 - mean_squared_error: 85.3277     \n",
      "Epoch 67/100\n",
      "404/404 [==============================] - 0s - loss: 85.0930 - mean_squared_error: 85.0930     \n",
      "Epoch 68/100\n",
      "404/404 [==============================] - 0s - loss: 84.9277 - mean_squared_error: 84.9277     \n",
      "Epoch 69/100\n",
      "404/404 [==============================] - 0s - loss: 85.0696 - mean_squared_error: 85.0696     \n",
      "Epoch 70/100\n",
      "404/404 [==============================] - 0s - loss: 84.9966 - mean_squared_error: 84.9966     \n",
      "Epoch 71/100\n",
      "404/404 [==============================] - 0s - loss: 85.1461 - mean_squared_error: 85.1461     \n",
      "Epoch 72/100\n",
      "404/404 [==============================] - 0s - loss: 84.9787 - mean_squared_error: 84.9787     \n",
      "Epoch 73/100\n",
      "404/404 [==============================] - 0s - loss: 85.5027 - mean_squared_error: 85.5027       \n",
      "Epoch 74/100\n",
      "404/404 [==============================] - 0s - loss: 84.8605 - mean_squared_error: 84.8605     \n",
      "Epoch 75/100\n",
      "404/404 [==============================] - 0s - loss: 85.1596 - mean_squared_error: 85.1596     \n",
      "Epoch 76/100\n",
      "404/404 [==============================] - 0s - loss: 85.0755 - mean_squared_error: 85.0755     \n",
      "Epoch 77/100\n",
      "404/404 [==============================] - 0s - loss: 84.9410 - mean_squared_error: 84.9410     \n",
      "Epoch 78/100\n",
      "404/404 [==============================] - 0s - loss: 85.4107 - mean_squared_error: 85.4107     \n",
      "Epoch 79/100\n",
      "404/404 [==============================] - 0s - loss: 85.5117 - mean_squared_error: 85.5117       \n",
      "Epoch 80/100\n",
      "404/404 [==============================] - 0s - loss: 85.8356 - mean_squared_error: 85.8356       \n",
      "Epoch 81/100\n",
      "404/404 [==============================] - 0s - loss: 84.9862 - mean_squared_error: 84.9862       \n",
      "Epoch 82/100\n",
      "404/404 [==============================] - 0s - loss: 85.2702 - mean_squared_error: 85.2702     \n",
      "Epoch 83/100\n",
      "404/404 [==============================] - 0s - loss: 85.4438 - mean_squared_error: 85.4438     \n",
      "Epoch 84/100\n",
      "404/404 [==============================] - 0s - loss: 85.5597 - mean_squared_error: 85.5597     \n",
      "Epoch 85/100\n",
      "404/404 [==============================] - 0s - loss: 85.0580 - mean_squared_error: 85.0580     \n",
      "Epoch 86/100\n",
      "404/404 [==============================] - 0s - loss: 84.8265 - mean_squared_error: 84.8265     \n",
      "Epoch 87/100\n",
      "404/404 [==============================] - 0s - loss: 85.1173 - mean_squared_error: 85.1173       \n",
      "Epoch 88/100\n",
      "404/404 [==============================] - 0s - loss: 84.7833 - mean_squared_error: 84.7833     \n",
      "Epoch 89/100\n",
      "404/404 [==============================] - 0s - loss: 85.2693 - mean_squared_error: 85.2693     \n",
      "Epoch 90/100\n",
      "404/404 [==============================] - 0s - loss: 84.7791 - mean_squared_error: 84.7791     \n",
      "Epoch 91/100\n",
      "404/404 [==============================] - 0s - loss: 85.0323 - mean_squared_error: 85.0323     \n",
      "Epoch 92/100\n",
      "404/404 [==============================] - 0s - loss: 85.1720 - mean_squared_error: 85.1720     \n",
      "Epoch 93/100\n",
      "404/404 [==============================] - 0s - loss: 85.0131 - mean_squared_error: 85.0131     \n",
      "Epoch 94/100\n",
      "404/404 [==============================] - 0s - loss: 85.0947 - mean_squared_error: 85.0947     \n",
      "Epoch 95/100\n",
      "404/404 [==============================] - 0s - loss: 84.9864 - mean_squared_error: 84.9864     \n",
      "Epoch 96/100\n",
      "404/404 [==============================] - 0s - loss: 86.1239 - mean_squared_error: 86.1239     \n",
      "Epoch 97/100\n",
      "404/404 [==============================] - 0s - loss: 84.9723 - mean_squared_error: 84.9723       \n",
      "Epoch 98/100\n",
      "404/404 [==============================] - 0s - loss: 85.0524 - mean_squared_error: 85.0524     \n",
      "Epoch 99/100\n",
      "404/404 [==============================] - 0s - loss: 84.7371 - mean_squared_error: 84.7371     \n",
      "Epoch 100/100\n",
      "404/404 [==============================] - 0s - loss: 85.1205 - mean_squared_error: 85.1205     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12fffeba8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 50, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation\n",
    "- Keras model can be evaluated with evaluate() function\n",
    "- Evaluation results are contained in a list\n",
    "    - Doc (metrics): https://keras.io/metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 32/102 [========>.....................] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'mean_squared_error']\n",
      "[83.25929320092295, 83.25929320092295]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)     # list of metric names the model is employing\n",
    "print(results)                 # actual figure of metrics computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  83.25929320092295\n",
      "mse:  83.25929320092295\n"
     ]
    }
   ],
   "source": [
    "print('loss: ', results[0])\n",
    "print('mse: ', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP for classification tasks\n",
    "- When the target (**y**) is discrete (categorical)\n",
    "- For loss function, cross-entropy is used and for evaluation metric, accuracy is commonly used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = whole_data.data\n",
    "y_data = whole_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.3, random_state = 7) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description\n",
    "- Breast cancer dataset has total 569 data instances (212 malign, 357 benign instances)\n",
    "- 30 attributes (features) to predict the binary class (M/B)\n",
    "- Doc: http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 30)\n",
      "(171, 30)\n",
      "(398,)\n",
      "(171,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creating a model\n",
    "- Same with regression model at the outset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Adding layers\n",
    "- Keras layers can be **added** to the model\n",
    "- Adding layers are like stacking lego blocks one by one\n",
    "- It should be noted that as this is a classification problem, sigmoid layer (softmax for multi-class problems) should be added\n",
    "- Doc: https://keras.io/layers/core/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras model with two hidden layer with 10 neurons each \n",
    "model.add(Dense(10, input_shape = (30,)))    # Input layer => input_shape should be explicitly designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1))                          # Output layer => output dimension = 1 since it is regression problem\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is equivalent to the above code block\n",
    "model.add(Dense(10, input_shape = (13,), activation = 'sigmoid'))\n",
    "model.add(Dense(10, activation = 'sigmoid'))\n",
    "model.add(Dense(10, activation = 'sigmoid'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Model compile\n",
    "- Keras model should be \"compiled\" prior to training\n",
    "- Types of loss (function) and optimizer should be designated\n",
    "    - Doc (optimizers): https://keras.io/optimizers/\n",
    "    - Doc (losses): https://keras.io/losses/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr = 0.01)    # stochastic gradient descent optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = sgd, loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 792.0\n",
      "Trainable params: 792.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training\n",
    "- Training the model with training data provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "398/398 [==============================] - 0s - loss: 0.6710 - acc: 0.6055     \n",
      "Epoch 2/100\n",
      "398/398 [==============================] - 0s - loss: 0.6710 - acc: 0.6055     \n",
      "Epoch 3/100\n",
      "398/398 [==============================] - 0s - loss: 0.6709 - acc: 0.6055     \n",
      "Epoch 4/100\n",
      "398/398 [==============================] - 0s - loss: 0.6709 - acc: 0.6055     \n",
      "Epoch 5/100\n",
      "398/398 [==============================] - 0s - loss: 0.6709 - acc: 0.6055     \n",
      "Epoch 6/100\n",
      "398/398 [==============================] - 0s - loss: 0.6709 - acc: 0.6055     \n",
      "Epoch 7/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 8/100\n",
      "398/398 [==============================] - 0s - loss: 0.6709 - acc: 0.6055     \n",
      "Epoch 9/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 10/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 11/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 12/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 13/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 14/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 15/100\n",
      "398/398 [==============================] - 0s - loss: 0.6709 - acc: 0.6055     \n",
      "Epoch 16/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 17/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 18/100\n",
      "398/398 [==============================] - 0s - loss: 0.6709 - acc: 0.6055     \n",
      "Epoch 19/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 20/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 21/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 22/100\n",
      "398/398 [==============================] - 0s - loss: 0.6709 - acc: 0.6055     \n",
      "Epoch 23/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 24/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 25/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 26/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 27/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 28/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 29/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 30/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 31/100\n",
      "398/398 [==============================] - 0s - loss: 0.6709 - acc: 0.6055     \n",
      "Epoch 32/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 33/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 34/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 35/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 36/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 37/100\n",
      "398/398 [==============================] - 0s - loss: 0.6707 - acc: 0.6055     \n",
      "Epoch 38/100\n",
      "398/398 [==============================] - 0s - loss: 0.6707 - acc: 0.6055     \n",
      "Epoch 39/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 40/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 41/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 42/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 43/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 44/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 45/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 46/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 47/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 48/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 49/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 50/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 51/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 52/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 53/100\n",
      "398/398 [==============================] - 0s - loss: 0.6707 - acc: 0.6055     \n",
      "Epoch 54/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 55/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 56/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 57/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 58/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 59/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 60/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 61/100\n",
      "398/398 [==============================] - 0s - loss: 0.6709 - acc: 0.6055     \n",
      "Epoch 62/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 63/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 64/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 65/100\n",
      "398/398 [==============================] - 0s - loss: 0.6707 - acc: 0.6055     \n",
      "Epoch 66/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 67/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 68/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 69/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 70/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 71/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 72/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 73/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 74/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 75/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 76/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 77/100\n",
      "398/398 [==============================] - 0s - loss: 0.6707 - acc: 0.6055     \n",
      "Epoch 78/100\n",
      "398/398 [==============================] - 0s - loss: 0.6707 - acc: 0.6055     \n",
      "Epoch 79/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 80/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 81/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 82/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 83/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 84/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 85/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 86/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 87/100\n",
      "398/398 [==============================] - 0s - loss: 0.6709 - acc: 0.6055     \n",
      "Epoch 88/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 89/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 90/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 91/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 92/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 93/100\n",
      "398/398 [==============================] - 0s - loss: 0.6707 - acc: 0.6055     \n",
      "Epoch 94/100\n",
      "398/398 [==============================] - 0s - loss: 0.6709 - acc: 0.6055     \n",
      "Epoch 95/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 96/100\n",
      "398/398 [==============================] - 0s - loss: 0.6707 - acc: 0.6055     \n",
      "Epoch 97/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 98/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 99/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 100/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13232b048>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 50, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation\n",
    "- Keras model can be evaluated with evaluate() function\n",
    "- Evaluation results are contained in a list\n",
    "    - Doc (metrics): https://keras.io/metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 32/171 [====>.........................] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[0.6395693376050358, 0.6783625724022848]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)     # list of metric names the model is employing\n",
    "print(results)                 # actual figure of metrics computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.6395693376050358\n",
      "accuracy:  0.6783625724022848\n"
     ]
    }
   ],
   "source": [
    "print('loss: ', results[0])\n",
    "print('accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
