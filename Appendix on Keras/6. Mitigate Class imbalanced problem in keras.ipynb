{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class-weighted Learning\n",
    "- Class-imbalance problem is actually a quite common problem. For instance, there are much more purchasers among mobile app users and much more non-criminals than criminals in society.\n",
    "- However, if class imbalance is too severe (i.e., training set is highly skewed), it is likely to  bear undesirable effects. \n",
    "    - For instance, algorithm will tend to vote for majority class, all the time.\n",
    "    - This is highly risky since we might lose track of purchasers among mobile app users and criminals, which are relatively rare among training instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "- Breast cancer dataset in ```sklearn```\n",
    "- doc: http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X_data = data.data.tolist()\n",
    "y_data = data.target.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of malignant instances (0):  212\n",
      "Number of benign instances (1):  357\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of malignant instances (0): \", Counter(y_data)[0])\n",
    "print(\"Number of benign instances (1): \", Counter(y_data)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete some of malignant instances to generate class-imbalance situation artificially\n",
    "for i in range(200):\n",
    "    if y_data[i] == 0:\n",
    "        X_data[i] = None\n",
    "        y_data[i] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = [x for x in X_data if x != None]\n",
    "y_data = [y for y in y_data if y != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of malignant instances (0):  108\n",
      "Number of benign instances (1):  357\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of malignant instances (0): \", Counter(y_data)[0])\n",
    "print(\"Number of benign instances (1): \", Counter(y_data)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(372, 30) (93, 30) (372,) (93,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(X_data), np.asarray(y_data), test_size = 0.2, random_state = 7) \n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing class weights\n",
    "- We compute class weights based on training dataset, and deliver as parameter when fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed class weights:  {0: 2.2409638554216866, 1: 0.643598615916955}\n"
     ]
    }
   ],
   "source": [
    "class_weights = dict(zip(np.unique(y_train), weights))\n",
    "print(\"Computed class weights: \", class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_mlp():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_shape = (X_train.shape[1],), activation = 'relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(optimizer = adam(lr = 0.001), loss = 'binary_crossentropy', metrics = ['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "372/372 [==============================] - 0s 761us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 2/100\n",
      "372/372 [==============================] - 0s 41us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 3/100\n",
      "372/372 [==============================] - 0s 42us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 4/100\n",
      "372/372 [==============================] - 0s 46us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 5/100\n",
      "372/372 [==============================] - 0s 46us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 6/100\n",
      "372/372 [==============================] - 0s 47us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 7/100\n",
      "372/372 [==============================] - 0s 45us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 8/100\n",
      "372/372 [==============================] - 0s 47us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 9/100\n",
      "372/372 [==============================] - 0s 45us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 10/100\n",
      "372/372 [==============================] - 0s 47us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 11/100\n",
      "372/372 [==============================] - 0s 66us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 12/100\n",
      "372/372 [==============================] - 0s 48us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 13/100\n",
      "372/372 [==============================] - 0s 52us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 14/100\n",
      "372/372 [==============================] - 0s 47us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 15/100\n",
      "372/372 [==============================] - 0s 57us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 16/100\n",
      "372/372 [==============================] - 0s 51us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 17/100\n",
      "372/372 [==============================] - 0s 48us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 18/100\n",
      "372/372 [==============================] - 0s 44us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 19/100\n",
      "372/372 [==============================] - 0s 48us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 20/100\n",
      "372/372 [==============================] - 0s 54us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 21/100\n",
      "372/372 [==============================] - 0s 54us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 22/100\n",
      "372/372 [==============================] - 0s 50us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 23/100\n",
      "372/372 [==============================] - 0s 59us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 24/100\n",
      "372/372 [==============================] - 0s 53us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 25/100\n",
      "372/372 [==============================] - 0s 54us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 26/100\n",
      "372/372 [==============================] - 0s 55us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 27/100\n",
      "372/372 [==============================] - 0s 52us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 28/100\n",
      "372/372 [==============================] - 0s 50us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 29/100\n",
      "372/372 [==============================] - 0s 50us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 30/100\n",
      "372/372 [==============================] - 0s 53us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 31/100\n",
      "372/372 [==============================] - 0s 48us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 32/100\n",
      "372/372 [==============================] - 0s 56us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 33/100\n",
      "372/372 [==============================] - 0s 44us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 34/100\n",
      "372/372 [==============================] - 0s 50us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 35/100\n",
      "372/372 [==============================] - 0s 47us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 36/100\n",
      "372/372 [==============================] - 0s 47us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 37/100\n",
      "372/372 [==============================] - 0s 39us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 38/100\n",
      "372/372 [==============================] - 0s 46us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 39/100\n",
      "372/372 [==============================] - 0s 48us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 40/100\n",
      "372/372 [==============================] - 0s 48us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 41/100\n",
      "372/372 [==============================] - 0s 43us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 42/100\n",
      "372/372 [==============================] - 0s 54us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 43/100\n",
      "372/372 [==============================] - 0s 50us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 44/100\n",
      "372/372 [==============================] - 0s 64us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 45/100\n",
      "372/372 [==============================] - 0s 41us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 46/100\n",
      "372/372 [==============================] - 0s 49us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 47/100\n",
      "372/372 [==============================] - 0s 52us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 48/100\n",
      "372/372 [==============================] - 0s 41us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 49/100\n",
      "372/372 [==============================] - 0s 47us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 50/100\n",
      "372/372 [==============================] - 0s 44us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 51/100\n",
      "372/372 [==============================] - 0s 47us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 52/100\n",
      "372/372 [==============================] - 0s 46us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 53/100\n",
      "372/372 [==============================] - 0s 46us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 54/100\n",
      "372/372 [==============================] - 0s 45us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 55/100\n",
      "372/372 [==============================] - 0s 43us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 56/100\n",
      "372/372 [==============================] - 0s 45us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 57/100\n",
      "372/372 [==============================] - 0s 45us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 58/100\n",
      "372/372 [==============================] - 0s 44us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 59/100\n",
      "372/372 [==============================] - 0s 48us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 60/100\n",
      "372/372 [==============================] - 0s 50us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 61/100\n",
      "372/372 [==============================] - 0s 49us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 62/100\n",
      "372/372 [==============================] - 0s 47us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 63/100\n",
      "372/372 [==============================] - 0s 60us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 64/100\n",
      "372/372 [==============================] - 0s 49us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 65/100\n",
      "372/372 [==============================] - 0s 44us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 66/100\n",
      "372/372 [==============================] - 0s 43us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 67/100\n",
      "372/372 [==============================] - 0s 39us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 68/100\n",
      "372/372 [==============================] - 0s 39us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 69/100\n",
      "372/372 [==============================] - 0s 37us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 70/100\n",
      "372/372 [==============================] - 0s 41us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 71/100\n",
      "372/372 [==============================] - 0s 39us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 72/100\n",
      "372/372 [==============================] - 0s 39us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 73/100\n",
      "372/372 [==============================] - 0s 41us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 74/100\n",
      "372/372 [==============================] - 0s 41us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 75/100\n",
      "372/372 [==============================] - 0s 42us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 76/100\n",
      "372/372 [==============================] - 0s 41us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 77/100\n",
      "372/372 [==============================] - 0s 40us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 78/100\n",
      "372/372 [==============================] - 0s 41us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 79/100\n",
      "372/372 [==============================] - 0s 38us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 80/100\n",
      "372/372 [==============================] - 0s 42us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 81/100\n",
      "372/372 [==============================] - 0s 41us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 82/100\n",
      "372/372 [==============================] - 0s 41us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372/372 [==============================] - 0s 43us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 84/100\n",
      "372/372 [==============================] - 0s 43us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 85/100\n",
      "372/372 [==============================] - 0s 39us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 86/100\n",
      "372/372 [==============================] - 0s 44us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 87/100\n",
      "372/372 [==============================] - 0s 41us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 88/100\n",
      "372/372 [==============================] - 0s 41us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 89/100\n",
      "372/372 [==============================] - 0s 42us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 90/100\n",
      "372/372 [==============================] - 0s 46us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 91/100\n",
      "372/372 [==============================] - 0s 45us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 92/100\n",
      "372/372 [==============================] - 0s 50us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 93/100\n",
      "372/372 [==============================] - 0s 44us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 94/100\n",
      "372/372 [==============================] - 0s 47us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 95/100\n",
      "372/372 [==============================] - 0s 45us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 96/100\n",
      "372/372 [==============================] - 0s 46us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 97/100\n",
      "372/372 [==============================] - 0s 50us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 98/100\n",
      "372/372 [==============================] - 0s 49us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 99/100\n",
      "372/372 [==============================] - 0s 50us/step - loss: 12.5219 - acc: 0.2231\n",
      "Epoch 100/100\n",
      "372/372 [==============================] - 0s 52us/step - loss: 12.5219 - acc: 0.2231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12a386d30>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = simple_mlp()\n",
    "model.fit(X_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of predicted 1's:  0.0\n",
      "Overall Accuracy Score:  0.26881720430107525\n"
     ]
    }
   ],
   "source": [
    "print(\"% of predicted 1's: \", y_pred.sum()/len(y_pred))\n",
    "print(\"Overall Accuracy Score: \", accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class-weighted learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "372/372 [==============================] - 0s 718us/step - loss: 6.7169 - acc: 0.3737\n",
      "Epoch 2/100\n",
      "372/372 [==============================] - 0s 44us/step - loss: 5.7320 - acc: 0.3306\n",
      "Epoch 3/100\n",
      "372/372 [==============================] - 0s 47us/step - loss: 4.5548 - acc: 0.5000\n",
      "Epoch 4/100\n",
      "372/372 [==============================] - 0s 47us/step - loss: 4.2774 - acc: 0.3548\n",
      "Epoch 5/100\n",
      "372/372 [==============================] - 0s 47us/step - loss: 3.3119 - acc: 0.5000\n",
      "Epoch 6/100\n",
      "372/372 [==============================] - 0s 52us/step - loss: 2.8563 - acc: 0.6667\n",
      "Epoch 7/100\n",
      "372/372 [==============================] - 0s 47us/step - loss: 2.4438 - acc: 0.6398\n",
      "Epoch 8/100\n",
      "372/372 [==============================] - 0s 48us/step - loss: 2.2266 - acc: 0.6640\n",
      "Epoch 9/100\n",
      "372/372 [==============================] - 0s 49us/step - loss: 2.0798 - acc: 0.7312\n",
      "Epoch 10/100\n",
      "372/372 [==============================] - 0s 51us/step - loss: 1.9788 - acc: 0.6774\n",
      "Epoch 11/100\n",
      "372/372 [==============================] - 0s 51us/step - loss: 1.8026 - acc: 0.7903\n",
      "Epoch 12/100\n",
      "372/372 [==============================] - 0s 42us/step - loss: 1.7429 - acc: 0.6989\n",
      "Epoch 13/100\n",
      "372/372 [==============================] - 0s 44us/step - loss: 1.9660 - acc: 0.8226\n",
      "Epoch 14/100\n",
      "372/372 [==============================] - 0s 50us/step - loss: 1.5849 - acc: 0.6989\n",
      "Epoch 15/100\n",
      "372/372 [==============================] - 0s 46us/step - loss: 1.4960 - acc: 0.8253\n",
      "Epoch 16/100\n",
      "372/372 [==============================] - 0s 67us/step - loss: 1.3355 - acc: 0.7957\n",
      "Epoch 17/100\n",
      "372/372 [==============================] - 0s 46us/step - loss: 1.4006 - acc: 0.8118\n",
      "Epoch 18/100\n",
      "372/372 [==============================] - 0s 46us/step - loss: 1.4403 - acc: 0.7742\n",
      "Epoch 19/100\n",
      "372/372 [==============================] - 0s 44us/step - loss: 1.2271 - acc: 0.7688\n",
      "Epoch 20/100\n",
      "372/372 [==============================] - 0s 43us/step - loss: 1.1650 - acc: 0.8656\n",
      "Epoch 21/100\n",
      "372/372 [==============================] - 0s 51us/step - loss: 1.1056 - acc: 0.8387\n",
      "Epoch 22/100\n",
      "372/372 [==============================] - 0s 55us/step - loss: 1.1155 - acc: 0.8548\n",
      "Epoch 23/100\n",
      "372/372 [==============================] - 0s 51us/step - loss: 1.1328 - acc: 0.8414\n",
      "Epoch 24/100\n",
      "372/372 [==============================] - 0s 59us/step - loss: 1.2129 - acc: 0.7581\n",
      "Epoch 25/100\n",
      "372/372 [==============================] - 0s 59us/step - loss: 1.2422 - acc: 0.8871\n",
      "Epoch 26/100\n",
      "372/372 [==============================] - 0s 57us/step - loss: 1.4366 - acc: 0.7231\n",
      "Epoch 27/100\n",
      "372/372 [==============================] - 0s 55us/step - loss: 1.0370 - acc: 0.8414\n",
      "Epoch 28/100\n",
      "372/372 [==============================] - 0s 51us/step - loss: 1.0284 - acc: 0.8602\n",
      "Epoch 29/100\n",
      "372/372 [==============================] - 0s 52us/step - loss: 1.0361 - acc: 0.7715\n",
      "Epoch 30/100\n",
      "372/372 [==============================] - 0s 50us/step - loss: 1.5595 - acc: 0.9059\n",
      "Epoch 31/100\n",
      "372/372 [==============================] - 0s 44us/step - loss: 1.2605 - acc: 0.8091\n",
      "Epoch 32/100\n",
      "372/372 [==============================] - 0s 48us/step - loss: 0.8226 - acc: 0.8387\n",
      "Epoch 33/100\n",
      "372/372 [==============================] - 0s 43us/step - loss: 0.9691 - acc: 0.8602\n",
      "Epoch 34/100\n",
      "372/372 [==============================] - 0s 40us/step - loss: 0.9930 - acc: 0.7930\n",
      "Epoch 35/100\n",
      "372/372 [==============================] - 0s 44us/step - loss: 1.0381 - acc: 0.8038\n",
      "Epoch 36/100\n",
      "372/372 [==============================] - 0s 46us/step - loss: 0.7621 - acc: 0.8629\n",
      "Epoch 37/100\n",
      "372/372 [==============================] - 0s 47us/step - loss: 0.7915 - acc: 0.8629\n",
      "Epoch 38/100\n",
      "372/372 [==============================] - 0s 53us/step - loss: 0.6932 - acc: 0.8387\n",
      "Epoch 39/100\n",
      "372/372 [==============================] - 0s 52us/step - loss: 0.7170 - acc: 0.8844\n",
      "Epoch 40/100\n",
      "372/372 [==============================] - 0s 49us/step - loss: 0.6874 - acc: 0.8683\n",
      "Epoch 41/100\n",
      "372/372 [==============================] - 0s 41us/step - loss: 0.6992 - acc: 0.8495\n",
      "Epoch 42/100\n",
      "372/372 [==============================] - 0s 50us/step - loss: 0.7811 - acc: 0.8817\n",
      "Epoch 43/100\n",
      "372/372 [==============================] - 0s 44us/step - loss: 0.6242 - acc: 0.8522\n",
      "Epoch 44/100\n",
      "372/372 [==============================] - 0s 45us/step - loss: 0.6895 - acc: 0.8978\n",
      "Epoch 45/100\n",
      "372/372 [==============================] - 0s 50us/step - loss: 0.6714 - acc: 0.8602\n",
      "Epoch 46/100\n",
      "372/372 [==============================] - 0s 41us/step - loss: 0.6344 - acc: 0.8952\n",
      "Epoch 47/100\n",
      "372/372 [==============================] - 0s 47us/step - loss: 0.7464 - acc: 0.8629\n",
      "Epoch 48/100\n",
      "372/372 [==============================] - 0s 42us/step - loss: 0.5659 - acc: 0.8548\n",
      "Epoch 49/100\n",
      "372/372 [==============================] - 0s 48us/step - loss: 0.5901 - acc: 0.8898\n",
      "Epoch 50/100\n",
      "372/372 [==============================] - 0s 40us/step - loss: 0.5461 - acc: 0.8978\n",
      "Epoch 51/100\n",
      "372/372 [==============================] - 0s 46us/step - loss: 0.5384 - acc: 0.8844\n",
      "Epoch 52/100\n",
      "372/372 [==============================] - 0s 45us/step - loss: 0.5330 - acc: 0.8978\n",
      "Epoch 53/100\n",
      "372/372 [==============================] - 0s 39us/step - loss: 0.6085 - acc: 0.8602\n",
      "Epoch 54/100\n",
      "372/372 [==============================] - 0s 44us/step - loss: 0.5596 - acc: 0.8683\n",
      "Epoch 55/100\n",
      "372/372 [==============================] - 0s 44us/step - loss: 0.8864 - acc: 0.8629\n",
      "Epoch 56/100\n",
      "372/372 [==============================] - 0s 43us/step - loss: 0.5557 - acc: 0.9005\n",
      "Epoch 57/100\n",
      "372/372 [==============================] - 0s 37us/step - loss: 0.5662 - acc: 0.8737\n",
      "Epoch 58/100\n",
      "372/372 [==============================] - 0s 37us/step - loss: 0.5592 - acc: 0.9059\n",
      "Epoch 59/100\n",
      "372/372 [==============================] - 0s 43us/step - loss: 0.7505 - acc: 0.8360\n",
      "Epoch 60/100\n",
      "372/372 [==============================] - 0s 45us/step - loss: 0.5440 - acc: 0.8602\n",
      "Epoch 61/100\n",
      "372/372 [==============================] - 0s 35us/step - loss: 0.4503 - acc: 0.9113\n",
      "Epoch 62/100\n",
      "372/372 [==============================] - 0s 40us/step - loss: 0.4661 - acc: 0.8898\n",
      "Epoch 63/100\n",
      "372/372 [==============================] - 0s 43us/step - loss: 0.4187 - acc: 0.9113\n",
      "Epoch 64/100\n",
      "372/372 [==============================] - 0s 42us/step - loss: 0.4001 - acc: 0.8710\n",
      "Epoch 65/100\n",
      "372/372 [==============================] - 0s 40us/step - loss: 0.7800 - acc: 0.8656\n",
      "Epoch 66/100\n",
      "372/372 [==============================] - 0s 43us/step - loss: 0.4778 - acc: 0.8871\n",
      "Epoch 67/100\n",
      "372/372 [==============================] - 0s 39us/step - loss: 0.4454 - acc: 0.8790\n",
      "Epoch 68/100\n",
      "372/372 [==============================] - 0s 39us/step - loss: 0.5190 - acc: 0.8683\n",
      "Epoch 69/100\n",
      "372/372 [==============================] - 0s 41us/step - loss: 0.4781 - acc: 0.8790\n",
      "Epoch 70/100\n",
      "372/372 [==============================] - 0s 40us/step - loss: 0.4142 - acc: 0.8871\n",
      "Epoch 71/100\n",
      "372/372 [==============================] - 0s 41us/step - loss: 0.3649 - acc: 0.9005\n",
      "Epoch 72/100\n",
      "372/372 [==============================] - 0s 57us/step - loss: 0.3757 - acc: 0.8978\n",
      "Epoch 73/100\n",
      "372/372 [==============================] - 0s 43us/step - loss: 0.3563 - acc: 0.9113\n",
      "Epoch 74/100\n",
      "372/372 [==============================] - 0s 38us/step - loss: 0.3655 - acc: 0.9005\n",
      "Epoch 75/100\n",
      "372/372 [==============================] - 0s 52us/step - loss: 0.3408 - acc: 0.9194\n",
      "Epoch 76/100\n",
      "372/372 [==============================] - 0s 46us/step - loss: 0.3747 - acc: 0.8737\n",
      "Epoch 77/100\n",
      "372/372 [==============================] - 0s 43us/step - loss: 0.5230 - acc: 0.8763\n",
      "Epoch 78/100\n",
      "372/372 [==============================] - 0s 45us/step - loss: 0.2652 - acc: 0.9274\n",
      "Epoch 79/100\n",
      "372/372 [==============================] - 0s 44us/step - loss: 0.4175 - acc: 0.9005\n",
      "Epoch 80/100\n",
      "372/372 [==============================] - 0s 46us/step - loss: 0.3244 - acc: 0.9140\n",
      "Epoch 81/100\n",
      "372/372 [==============================] - 0s 38us/step - loss: 0.2901 - acc: 0.9247\n",
      "Epoch 82/100\n",
      "372/372 [==============================] - 0s 44us/step - loss: 0.2875 - acc: 0.9167\n",
      "Epoch 83/100\n",
      "372/372 [==============================] - 0s 44us/step - loss: 0.2937 - acc: 0.9005\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372/372 [==============================] - 0s 48us/step - loss: 0.3624 - acc: 0.9140\n",
      "Epoch 85/100\n",
      "372/372 [==============================] - 0s 43us/step - loss: 0.2918 - acc: 0.9140\n",
      "Epoch 86/100\n",
      "372/372 [==============================] - 0s 43us/step - loss: 0.3377 - acc: 0.8898\n",
      "Epoch 87/100\n",
      "372/372 [==============================] - 0s 43us/step - loss: 0.2231 - acc: 0.9220\n",
      "Epoch 88/100\n",
      "372/372 [==============================] - 0s 45us/step - loss: 0.2616 - acc: 0.9194\n",
      "Epoch 89/100\n",
      "372/372 [==============================] - 0s 45us/step - loss: 0.2783 - acc: 0.9167\n",
      "Epoch 90/100\n",
      "372/372 [==============================] - 0s 43us/step - loss: 0.2664 - acc: 0.9247\n",
      "Epoch 91/100\n",
      "372/372 [==============================] - 0s 48us/step - loss: 0.2773 - acc: 0.9167\n",
      "Epoch 92/100\n",
      "372/372 [==============================] - 0s 42us/step - loss: 0.3613 - acc: 0.8763\n",
      "Epoch 93/100\n",
      "372/372 [==============================] - 0s 41us/step - loss: 0.2139 - acc: 0.9247\n",
      "Epoch 94/100\n",
      "372/372 [==============================] - 0s 42us/step - loss: 0.2549 - acc: 0.9247\n",
      "Epoch 95/100\n",
      "372/372 [==============================] - 0s 44us/step - loss: 0.2141 - acc: 0.9301\n",
      "Epoch 96/100\n",
      "372/372 [==============================] - 0s 46us/step - loss: 0.2045 - acc: 0.9409\n",
      "Epoch 97/100\n",
      "372/372 [==============================] - 0s 44us/step - loss: 0.2100 - acc: 0.9220\n",
      "Epoch 98/100\n",
      "372/372 [==============================] - 0s 43us/step - loss: 0.2624 - acc: 0.9032\n",
      "Epoch 99/100\n",
      "372/372 [==============================] - 0s 41us/step - loss: 0.2421 - acc: 0.9167\n",
      "Epoch 100/100\n",
      "372/372 [==============================] - 0s 42us/step - loss: 0.2321 - acc: 0.9301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12a886780>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = simple_mlp()\n",
    "model.fit(X_train, y_train, epochs = 100, class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of predicted 1's:  0.7096774193548387\n",
      "Overall Accuracy Score:  0.9354838709677419\n"
     ]
    }
   ],
   "source": [
    "print(\"% of predicted 1's: \", y_pred.sum()/len(y_pred))\n",
    "print(\"Overall Accuracy Score: \", accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
